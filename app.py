import os
import streamlit as st
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain.chains import LLMChain
from typing import List

# Load .env if exists (for LOCAL development)
load_dotenv()

# --- Helper functions -------------------------------------------------------

def build_prompt_template(platform: str, tone: str, description: str, num_variants: int, language: str = "æ—¥æœ¬èª") -> ChatPromptTemplate:
    system_message = f"""
You are an expert copywriter for social media. 
Given a content description, generate {num_variants} unique short captions tailored for {platform} in a {tone} tone.
Each caption should:
- Fit typical length constraints of {platform} (keep it concise)
- Include 1-3 relevant hashtags at the end
- Be distinct from each other
Return the captions as a numbered list (1., 2., ...) with the caption only (no extra explanation).
"""

    human_template = """
Content description:
{description}
"""

    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessagePromptTemplate.from_template(system_message),
            HumanMessagePromptTemplate.from_template(human_template),
        ]
    )
    return prompt

def parse_captions(raw: str) -> List[str]:
    # Simple split by lines starting with number or dash
    lines = [line.strip() for line in raw.strip().splitlines() if line.strip()]
    captions = []
    for line in lines:
        # remove leading "1. " or "2)" etc.
        cleaned = line
        if cleaned[0].isdigit():
            # find first dot or parenthesis
            if "." in cleaned:
                cleaned = cleaned.split(".", 1)[1].strip()
            elif ")" in cleaned:
                cleaned = cleaned.split(")", 1)[1].strip()
        captions.append(cleaned)
    return captions

# --- Streamlit UI ----------------------------------------------------------

st.set_page_config(page_title="SNS ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿", layout="centered")

st.title("ğŸ“¸ SNSæŠ•ç¨¿ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿")
st.markdown(
    """
çŸ­ã„èª¬æ˜ã‹ã‚‰æŒ‡å®šã®ãƒˆãƒ¼ãƒ³ãƒ»ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å‘ã‘ã«ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ¡ˆã‚’è¤‡æ•°ç”Ÿæˆã—ã¾ã™ã€‚  
ã‚³ãƒ”ãƒ¼ã—ã¦ãã®ã¾ã¾ä½¿ãˆã‚‹å½¢å¼ã§å‡ºåŠ›ã€‚  
"""
)

with st.form("caption_form"):
    description = st.text_area("æŠ•ç¨¿å†…å®¹ã®èª¬æ˜ï¼ˆä¾‹ï¼šæµ·ã§ã®é€±æœ«ã®å†™çœŸã€ã‚³ãƒ¼ãƒ’ãƒ¼ã¨èª­æ›¸ã®æ™‚é–“ãªã©ï¼‰", max_chars=500)
    col1, col2, col3 = st.columns(3)
    with col1:
        platform = st.selectbox("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆSNSãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ", ["Instagram", "Twitter", "X", "Facebook", "TikTok", "LinkedIn", "Threads"])
    with col2:
        tone = st.selectbox("ãƒˆãƒ¼ãƒ³", ["ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«", "ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒŠãƒ«", "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«", "ãƒ¦ãƒ¼ãƒ¢ãƒ©ã‚¹", "ã‚·ãƒ³ãƒ—ãƒ«", "æƒ…ç†±çš„"])
    with col3:
        language = st.selectbox("è¨€èª", ["æ—¥æœ¬èª", "English"])
    num_variants = st.slider("ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ¡ˆã®æ•°", min_value=3, max_value=8, value=5)
    submitted = st.form_submit_button("ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ")

if not os.getenv("OPENAI_API_KEY"):
    st.warning("ç’°å¢ƒå¤‰æ•° `OPENAI_API_KEY` ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

if submitted:
    if not description.strip():
        st.error("èª¬æ˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    with st.spinner("ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆä¸­..."):
        try:
            # ãƒ¢ãƒ‡ãƒ«ã¯å¿…è¦ã«å¿œã˜ã¦ 'gpt-4o' ã‚„ 'gpt-4o-mini' ãªã©ã«å¤‰ãˆã‚‰ã‚Œã‚‹
            llm = ChatOpenAI(temperature=0.7, model_name="gpt-4o", max_tokens=400)
            prompt = build_prompt_template(platform=platform, tone=tone, description=description, num_variants=num_variants, language=language)
            chain = LLMChain(llm=llm, prompt=prompt)

            raw_output = chain.run({"description": description})
            captions = parse_captions(raw_output)
            if not captions:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šç”Ÿã®å‡ºåŠ›ã‚’1ã¤ã ã‘
                captions = [raw_output.strip()]

        except Exception as e:
            st.exception(f"ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()

    st.subheader("ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ¡ˆ")
    for idx, cap in enumerate(captions[:num_variants], start=1):
        st.markdown(f"**{idx}.** {cap}")
        st.code(cap, language="text")
        st.markdown("---")

    # ã‚³ãƒ”ãƒ¼ç”¨ã¾ã¨ã‚
    st.subheader("ã¾ã¨ã‚ã¦ã‚³ãƒ”ãƒ¼")
    joined = "\n".join([f"{i}. {c}" for i, c in enumerate(captions[:num_variants], start=1)])
    st.text_area("å…¨æ¡ˆï¼ˆã‚³ãƒ”ãƒ¼ç”¨ï¼‰", value=joined, height=200)

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼šæ–‡ç« è¦ç´„ï¼ˆå…ƒèª¬æ˜ã®çŸ­ç¸®ç‰ˆï¼‰
    st.subheader("èª¬æ˜ã®è¦ç´„ï¼ˆä»»æ„ï¼‰")
    try:
        summary_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                "ã‚ãªãŸã¯æ—¥æœ¬èªã®è¦ç´„ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹èª¬æ˜ã‚’èª­ã¿ã€èª­ã¿æ‰‹ã«ä¼ã‚ã‚Šã‚„ã™ã„è‡ªç„¶ãªæ—¥æœ¬èªã§ã€çŸ­ãä¸€æ–‡ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
            ),
            HumanMessagePromptTemplate.from_template("{description}")
        ])
        summary_chain = LLMChain(llm=llm, prompt=summary_prompt)
        summary = summary_chain.run({"description": description})
        st.info(f"è¦ç´„: {summary.strip()}")
    except Exception:
        st.info("è¦ç´„ã¯ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")